,full_name,link,description,stars,forks,watchers,keywords,source
0,Annocript,https://github.com/frankMusacchia/Annocript.git,"Annocript is a pipeline for the annotation of de-novo generated  transcriptomes. It executes BLAST analysis with UniProt, NCBI Conserved Domain Database and Nucleotide divisions, Gene Ontology, UniPathways and the Enzyme Commission. It gives information about the longest ORF (using DNA2PEP) and non-coding potential of the sequences (using Portrait). A final heuristic makes Annocript able to identify putative long non-coding RNAs among your transcripts. Like our facebook page to be always updated: https://www.facebook.com/annocript",51,28,51,database+sequence+analysis,GitHub
1,BIGSdb,https://github.com/kjolley/BIGSdb.git,Bacterial Isolate Genome Sequence Database (BIGSdb) - A platform for gene-by-gene bacterial population annotation and analysis.,29,11,29,database+sequence+analysis+bacteria+genomes+database+mlst,GitHub
2,Gratton_et_al_JBiogeogr_2016,https://github.com/paolo-gratton/Gratton_et_al_JBiogeogr_2016.git,"Analysis pipeline for Gratton et al. (2016) ""A world of sequences: can we use georeferenced nucleotide databases for a robust automated phylogeography?"" Journal of Biogeography",4,5,4,database+sequence+analysis,GitHub
3,FluLINE,https://github.com/UmaSangumathi/FluLINE.git,"Flu analysis pipeline: i) Filtering of the sequencing reads by cutadapt and FastQC ii) Find the nearest sequence in NCBI database for each read, iii) Cluster and identify the viral species, iv) Generate consensus genomic sequence iteratively, v) Map the reads to the final consensus genome, vi) Identify SNVs and vii) Visualize the coverage of the genome ",4,3,4,database+sequence+analysis,GitHub
4,soap-hla,https://github.com/adefelicibus/soap-hla.git,SOAP-HLA is a flow of sequencing data analysis pipeline to type all of the HLA genes in IMGT/HLA database using capture sequenced data or WGS data with high accuracy.,3,1,3,database+sequence+analysis,GitHub
5,Machine-Learning-Interview-Preparation,https://github.com/reddyprasade/Machine-Learning-Interview-Preparation.git,"Prepare to Technical Skills Here are the essential skills that a Machine Learning Engineer needs, as mentioned Read me files. Within each group are topics that you should be familiar with.  Study Tip: Copy and paste this list into a document and save to your computer for easy referral.  Computer Science Fundamentals and Programming Topics  Data structures: Lists, stacks, queues, strings, hash maps, vectors, matrices, classes & objects, trees, graphs, etc. Algorithms: Recursion, searching, sorting, optimization, dynamic programming, etc. Computability and complexity: P vs. NP, NP-complete problems, big-O notation, approximate algorithms, etc. Computer architecture: Memory, cache, bandwidth, threads & processes, deadlocks, etc. Probability and Statistics Topics  Basic probability: Conditional probability, Bayes rule, likelihood, independence, etc. Probabilistic models: Bayes Nets, Markov Decision Processes, Hidden Markov Models, etc. Statistical measures: Mean, median, mode, variance, population parameters vs. sample statistics etc. Proximity and error metrics: Cosine similarity, mean-squared error, Manhattan and Euclidean distance, log-loss, etc. Distributions and random sampling: Uniform, normal, binomial, Poisson, etc. Analysis methods: ANOVA, hypothesis testing, factor analysis, etc. Data Modeling and Evaluation Topics  Data preprocessing: Munging/wrangling, transforming, aggregating, etc. Pattern recognition: Correlations, clusters, trends, outliers & anomalies, etc. Dimensionality reduction: Eigenvectors, Principal Component Analysis, etc. Prediction: Classification, regression, sequence prediction, etc.; suitable error/accuracy metrics. Evaluation: Training-testing split, sequential vs. randomized cross-validation, etc. Applying Machine Learning Algorithms and Libraries Topics  Models: Parametric vs. nonparametric, decision tree, nearest neighbor, neural net, support vector machine, ensemble of multiple models, etc. Learning procedure: Linear regression, gradient descent, genetic algorithms, bagging, boosting, and other model-specific methods; regularization, hyperparameter tuning, etc. Tradeoffs and gotchas: Relative advantages and disadvantages, bias and variance, overfitting and underfitting, vanishing/exploding gradients, missing data, data leakage, etc. Software Engineering and System Design Topics  Software interface: Library calls, REST APIs, data collection endpoints, database queries, etc. User interface: Capturing user inputs & application events, displaying results & visualization, etc. Scalability: Map-reduce, distributed processing, etc. Deployment: Cloud hosting, containers & instances, microservices, etc. Move on to the final lesson of this course to find lots of sample practice questions for each topic!",3,0,3,database+sequence+analysis,GitHub
6,motif_databases,https://github.com/rsa-tools/motif_databases.git,Databases of transcription factor binding motifs for the software suite Regulatory Sequence Analysis Tools (RSAT),1,2,1,database+sequence+analysis,GitHub
7,SContent,https://github.com/co2e14/SContent.git,Sulphur content analysis of large sequence databases,1,0,1,database+sequence+analysis,GitHub
8,GAG-Prospector,https://github.com/ywsheng227/GAG-Prospector.git,A Tool for Mining Glycosaminoglycan (GAG) Sequence Databases for Mass Spectrometry Data Analysis,1,1,1,database+sequence+analysis,GitHub
9,journey-neo4j-plugin,https://github.com/journey-app/journey-neo4j-plugin.git,This is a neo4j server plugin to turning the graph database to an action sequence analysis engine.,1,0,1,database+sequence+analysis,GitHub
10,Robot-learning,https://github.com/Aryia-Behroziuan/Robot-learning.git,"In developmental robotics, robot learning algorithms generate their own sequences of learning experiences, also known as a curriculum, to cumulatively acquire new skills through self-guided exploration and social interaction with humans. These robots use guidance mechanisms such as active learning, maturation, motor synergies and imitation.  Association rules Main article: Association rule learning See also: Inductive logic programming Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of ""interestingness"".[60]  Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves ""rules"" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[61] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.  Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieli≈Ñski and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[62] For example, the rule {\displaystyle \{\mathrm {onions,potatoes} \}\Rightarrow \{\mathrm {burger} \}}\{{\mathrm  {onions,potatoes}}\}\Rightarrow \{{\mathrm  {burger}}\} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.  Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[63]  Inductive logic programming (ILP) is an approach to rule-learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.  Inductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[64][65][66] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[67] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.  Models Performing machine learning involves creating a model, which is trained on some training data and then can process additional data to make predictions. Various types of models have been used and researched for machine learning systems.  Artificial neural networks Main article: Artificial neural network See also: Deep learning  An artificial neural network is an interconnected group of nodes, akin to the vast network of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another. Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems ""learn"" to perform tasks by considering examples, generally without being programmed with any task-specific rules.  An ANN is a model based on a collection of connected units or nodes called ""artificial neurons"", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a ""signal"", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called ""edges"". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.  The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.  Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[68]",1,0,1,database+sequence+analysis+aryia-behroziuan+artificial-intelligence+robot-learning+android+blog+csharp+data-science+express+flask+golang+nodejs+machine-learning+python,GitHub
11,Protein_Structure_Analysis,https://github.com/miotomato/Protein_Structure_Analysis.git,Sequence and Structure Database Creation and Analysis,0,0,0,database+sequence+analysis,GitHub
12,MetaPathways_Python_Koonkie.3.0,https://github.com/Koonkie/MetaPathways_Python_Koonkie.3.0.git,"MetaPathways is a meta'omic analysis pipeline for the annotation and analysis for environmental sequence information.  MetaPathways is a modular annotation and analysis pipeline that uses a user-friendly graphical user interface and knowledge engine data structure to predict metabolic interaction networks from environmental sequence information. Currently, MetaPathways supports genomic read quality control, open reading frame (ORF) prediction, ORF annotation, and environmental pathway-genomes database (ePGDB) construction compatible with the Pathway Tools browser by SRI.    ",0,3,0,database+sequence+analysis,GitHub
13,TOOLS_Document,https://github.com/alizaansari/TOOLS_Document.git,"Analysis tools, Design tools, Project management tools, Database tools, Documentation tools & Sequence diagram.",0,0,0,database+sequence+analysis,GitHub
14,MetaPathways_Python.3.0,https://github.com/kishori82/MetaPathways_Python.3.0.git,"MetaPathways is a meta'omic analysis pipeline for the annotation and analysis for environmental sequence information.  MetaPathways is a modular annotation and analysis pipeline that uses a user-friendly graphical user interface and knowledge engine data structure to predict metabolic interaction networks from environmental sequence information. Currently, MetaPathways supports genomic read quality control, open reading frame (ORF) prediction, ORF annotation, and environmental pathway-genomes database (ePGDB) construction compatible with the Pathway Tools browser by SRI.    ",0,2,0,database+sequence+analysis,GitHub
15,TP53-Multiple-Sequence-Alignment-Analysis,https://github.com/idrissrasheed/TP53-Multiple-Sequence-Alignment-Analysis.git,This pipeline extracts and aligns multiple sequences from the GenBank database and creates a FASTA file for multiple sequence alignment analysis. ,0,0,0,database+sequence+analysis,GitHub
16,entrez,https://github.com/kaiser0906/entrez.git,A python application retrieves sequence record in the GenBank databases for DNA and protein sequences and perform a simple string-based analysis of the data.,0,0,0,database+sequence+analysis,GitHub
17,whocc-sequences,https://github.com/acorg/whocc-sequences.git,"Set of tools to keep WHO CCs flu sequence database (H1, H3, B) and perform various analysis",0,0,0,database+sequence+analysis,GitHub
18,BMC-Pr2-RutasMetabolicas,https://github.com/jmaq-cr/BMC-Pr2-RutasMetabolicas.git,"Project oriented to the analysis and comparison of metabolic pathways, obtained from biological databases, and processed through graphs and sequence comparison.",0,0,0,database+sequence+analysis,GitHub
19,Protein_Conservation_Analysis,https://github.com/TheDataDiver/Protein_Conservation_Analysis.git,"Protein Conservation analysis, by selecting a family of protein sequences from a user-defined subset of the taxonomic tree, which would subsequently be processed, and used to plot and determine the level of protein sequence conservation, across species within the user-defined taxonomic group. Following which, these plotted sequences are then scanned with motifs from the PROSITE database, to identify if any known motifs (domains) are associated with these sequences.",0,0,0,database+sequence+analysis,GitHub
20,PTM_crosstalk_motif,https://github.com/maopeng2018/PTM_crosstalk_motif.git,"The PTMs_Motif project is freely available bioinformatics software platform to comprehensive analysis sequence motif of protein post translation modifications cross-talk. The project include two important parts: 1, extract PTM combination motifs from large scale dateset of PhosphositePlus database. 2, calculation motif evolutionary conservation score by comparing homologous protein sequences of 15 vetebrates.",0,0,0,database+sequence+analysis,GitHub
21,PARS,https://github.com/JuliaGol/PARS.git,"PARS is a python package for browsing and downloading files deposed in Pfam and Rfam databases (e.g. sequences, alignments, hmm). It has implemented classes dedicated to Pfam data like: PfamFamily or PfamClan. PARS is compatible with Biopython modules, but also is extended by HMMER wrapper which enables convenient usage of downloaded HMM files. One of the advantages of this package is the easy switch to other databases by translation of accession numbers. All of these features enable to make a detailed analysis of proteins or RNA families and deal with large datasets.",0,2,0,database+sequence+analysis+pfam+rfam+bioinformatics,GitHub
22,Genomics-Final-Project-Data-and-References,https://github.com/BluedragonXVI/Genomics-Final-Project-Data-and-References.git,"Senior Thesis: Multidimensional Scaling Analysis of Voltage-Gated Ion Channels Using R Represented genomic data of sodium channel sequences as points in a 3D space with MDS using the bios2mds R package and imported, cleaned and formatted amino acid sequences from the BLOCKS database into custom MSA files that were then analyzed via a BLOSUM matrix to produce a rotating plot of protein sequence dissimilarity. ",0,0,0,database+sequence+analysis,GitHub
23,Protein-Sequence-Analysis,https://github.com/biomart123/Protein-Sequence-Analysis.git,"Creative BioMart, with a successful track record of offering more than ten thousand custom bioinformatics consultations, provides protein sequence analysis of proteins by classifying them into families and predicting domains and important sites. On top of our advanced technologies in bioinformatics, we combine protein signatures from a number of member databases into a single searchable resource, capitalising on their individual strengths to produce a powerful integrated database and diagnostic tool.",0,0,0,database+sequence+analysis,GitHub
24,Galaxy-Integrated-variant-analysis,https://github.com/Lakshmanwadhwani/Galaxy-Integrated-variant-analysis.git,"Reproducible pipelines that create an integrated genomic profile of a cancer and use the profile to find mutations associated with disease and potentially useful drugs. These pipelines analyze high‚Äêthroughput cancer exome and transcriptome sequence data together with public databases to find relevant mutations and drugs. The three pipelines that developed are: (1) an exome analysis pipeline, which uses whole or targeted tumor exome sequence data to produce a list of putative variants (no matched normal data are needed); (2) a transcriptome analysis pipeline that processes whole tumor transcriptome sequence (RNA‚Äêseq) data to compute gene expression and find potential gene fusions; and (3) an integrated variant analysis pipeline that uses the tumor variants from the exome pipeline and tumor gene expression from the transcriptome pipeline to identify deleterious and druggable mutations in all genes and in highly expressed genes",0,0,0,database+sequence+analysis,GitHub
25,seq-align-bwa,https://github.com/ramibaghdan/seq-align-bwa.git,"In this analysis, sequence data (100 bp reads from the freshwater burbot fish) attained from Illumina HiSeq 2500 are aligned to different reference genomes using bwa to compare alignment rates. The two reference genomes used are the highly fragmented burbot genome in the NCBI database (with a low N50) and a well-developed cod genome (closely related to burbot). The sequence reads from freshwater burbot fish are aligned to both the Gadus morhua complete genome and the new burbot genome to observe variation in alignment rates between individuals and references.",0,0,0,database+sequence+analysis,GitHub
26,asap2,https://github.com/tianrenmaogithub/asap2.git,"Amplicon sequencing of marker genes such as 16S rDNA, 18S rDNA, ITS and others has been widely used to survey and characterize microbial communities in countless ecological and environmental studies. However, the complex data analyses have required many interfering manual steps often leading to inconsistencies in results. Here, we have developed a pipeline, amplicon sequence analysis pipeline 2 (ASAP 2), to automate and glide through the processes without the usual manual inspections and user‚Äôs interference, for instance, in the detection of barcode orientation, selection of high-quality region of reads, and determination of resampling depth and many more. The pipeline integrates all the analytical processes such as importing data, demultiplexing, summarizing read profiles, trimming quality, denoising, removing chimeric sequences, and making the feature (ASV) table among others, using QIIME 2, Vegan and other tools. The pipeline accepts multiple file formats as input including multiplexed or demultiplexed, paired-end or single-end, barcode inside or outside and raw or intermediate data (e.g. feature table). The outputs include taxonomic classification, alpha/beta diversity, community composition, ordination analysis and statistical tests (variable selection, CCA, RDA, etc.). ASAP 2 supports merging multiple sequencing runs which helps integrate and compare data from different sources (public databases and collaborators). The pipeline minimizes hands-on interference and runs amplicon sequencing analysis automatically and consistently.",0,0,0,database+sequence+analysis,GitHub
27,CS273a_EnhancersProject,https://github.com/LizIzhikevich/CS273a_EnhancersProject.git,"Predicting the function of different regions of the genome is one of the grand challenges of genomics. In this project, you will use an existing database of tested enhancers to devise a strategy for predicting novel enhancers, using both sequence features and numerous epigenetic marks. The advent of ChIP-seq has empowered high resolution genome-wide identification of the regions with specific marks, and correlation with functional annotation has identified combinations of marks that are characteristic of active and repressed genes, enhancers, repressors, and other types of functional elements (Ernst et al 2011 ‚ÄúMapping and analysis of chromatin state dynamics in nine human cell types.‚Äù). Here, you will be leveraging assays of many different marks in many different tissues to predict enhancers. In doing so, you should also identify which marks, or combinations of marks, are most discriminative in predicting enhancers.",0,0,0,database+sequence+analysis,GitHub
28,association-rule-learning,https://github.com/sayantann11/association-rule-learning.git,"Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness.[1]  Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieli≈Ñski and Arun Swami[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets. For example, the rule {\displaystyle \{\mathrm {onions,potatoes} \}\Rightarrow \{\mathrm {burger} \}}\{{\mathrm  {onions,potatoes}}\}\Rightarrow \{{\mathrm  {burger}}\} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as, e.g., promotional pricing or product placements.  In addition to the above example from market basket analysis association rules are employed today in many application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.",0,0,0,database+sequence+analysis,GitHub
29,Market-basket-analysis,https://github.com/jabirkangarli/Market-basket-analysis.git,"Introduction Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness.[1]  Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieli≈Ñski and Arun Swami[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets. For example, the rule {onions,potatoes}={burger}, {onions,potatoes}={burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as, e.g., promotional pricing or product placements.  In addition to the above example from market basket analysis association rules are employed today in many application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.  https://en.wikipedia.org/wiki/Association_rule_learning",0,0,0,database+sequence+analysis,GitHub
30,Data-Therapist-Detect-and-Fix-,https://github.com/wezzat/Data-Therapist-Detect-and-Fix-.git,"Is a set of open source tools and programs that can run on any platform to detect the corruption in data online and fix most of it transparently while the system is up and running without compromising the system availability. DT (Data Therapist) has been used in different industries and proven its success across platform and with different datatypes such as: char, nchar, nvarchar2, varchar, long, raw, long raw, number, numeric, float, decimal, integer, double precision, etc. The main objective of Data Therapist platform is to provide Database Administrators, Data analysis and IT Managers best practice recommendations for configuring key parameters, database features, system features and operational practices to enable best corruption detection, prevention, and automatic repair, in a MAA (Maximum Availability Architecture) or Data Guard configuration. This platform also provides additional background information on each parameter and performance consideration. Data Therapist (Detect and Fix) platform can deal with all types data corruption across different database systems running on different Operating System by detecting the suspicious data blocks, determine if they are really corrupted, specify whether the corruption is logical or physical and fix the corruption online while the system is up and running. The theory behind Data Therapist is simple, however it is so powerful, it is based on data detection algorithm that expect the data within a data block by knowing the data in the previous and next block to the suspicious block, from the data chain/sequence as well as its checksum it can detect and expect the corrupted data and fix it online. ",0,0,0,database+sequence+analysis,GitHub
31,adfa2,https://github.com/djdprogramming/adfa2.git,"# David's Personal Roadmap to Learning Data Science #### Based on the article [Learn Data Science for free in 2021](https://www.kdnuggets.com/2021/01/learn-data-science-free-2021.html) from KDnuggets. Some additions have been made. ###### I'm new to data science and programming. Some areas of study in this roadmap may be researched to a point of redundancy while materials for other topics could be seriously lacking. As I progress through this learning path, I'll be able to gauge which areas need more (or less) focus and will add and remove resources as needed.  ## Schoolwork ##### Required readings for my Data Science classes. - [ ] [Doing Data Science: Straight Talk from the Frontline](https://www.amazon.com/Doing-Data-Science-Straight-Frontline/dp/1449358659) by Cathy O'Neil & Rachel Schutt   - [ ] 1. Introduction: What is Data Science?   - [ ] 2. Statistical Inference, Exploratory Data Analysis, and the Data Science Process   - [ ] 3. Algorithms   - [ ] 4. Spam Filters, Naive Bayes, and Wrangling   - [ ] 5. Logistic Regression   - [ ] 6. Time Stamps and Financial Modeling   - [ ] 7. Extracting Meaning from Data   - [ ] 8. Recommendation Engines: Building a User-Facing Data Product at Scale   - [ ] 9. Data Visualization and Fraud Detection   - [ ] 10. Social Networks and Data Journalism   - [ ] 11. Causality   - [ ] 12. Epidemiology   - [ ] 13. Lessons Learned from Data Competitions: Data Leakage and Model Evaluation   - [ ] 14. Data Engineering: MapReduce, Pregel, and Hadoop   - [ ] 15. The Students Speak   - [ ] 16. Next-Generation Data Scientists, Hubris, and Ethics   - [ ] [Practical Statistics for Data Scientists: 50 Essential Concepts](https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/149207294X/ref=sr_1_1?dchild=1&keywords=Practical+Statistics+for+Data+Scientists&qid=1609991269&s=books&sr=1-1) by Peter Bruce, Andrew Bruce & Peter Gedeck   - [ ] 1. Exploratory Data Analysis   - [ ] 2. Data and Sampling Distributions   - [ ] 3. Statistical Experiments and Significance Testing   - [ ] 4. Regression and Prediction   - [ ] 5. Classification   - [ ] 6. Statistical Machine Learning   - [ ] 7. Unsupervised Learning  ## Programming Skills ##### Learn programming basics. - [ ] [Python 3 Basics Tutorial Series](https://www.youtube.com/playlist?list=PLQVvvaa0QuDe8XSftW-RAxdo6OmaeL85M) by sentdex   - [ ] 1. Python 3 Programming Tutorial: Why Python 3? Python 2 vs Python 3 `7:36`   - [ ] 2. Python 3 Programming Tutorial: Installing Python 3 - How to Install Both Python 2 and Python 3 `15:47`   - [ ] 3. Python 3 Programming Tutorial: Print Function and Strings `9:31`   - [ ] 4. Python 3 Programming Tutorial: Math `4:49`   - [ ] 5. Python 3 Programming Tutorial: Variables `4:26`   - [ ] 6. Python 3 Programming Tutorial: While Loop `5:55`   - [ ] 7. Python 3 Programming Tutorial: For Loop `9:05`   - [ ] 8. Python 3 Programming Tutorial: If Statement `4:54`   - [ ] 9. Python 3 Programming Tutorial: If Else `3:20`   - [ ] 10. Python 3 Programming Tutorial: If Elif Else `4:19`   - [ ] 11. Python 3 Programming Tutorial: Functions `3:05`   - [ ] 12. Python 3 Programming Tutorial: Function Parameters `4:00`   - [ ] 13. Python 3 Programming Tutorial: Function Parameter Defaults `6:06`   - [ ] 14. Python 3 Programming Tutorial: Global and Local Variables `6:31`   - [ ] 15. Python 3 Programming Tutorial: Installing Modules `7:44`   - [ ] 16. Python 3 Programming Tutorial: How to Download and Install Python Packages and Modules with Pip `8:32`   - [ ] 17. Python 3 Programming Tutorial: Common Errors `4:49`   - [ ] 18. Python 3 Programming Tutorial: Writing to File `3:35`   - [ ] 19. Python 3 Programming Tutorial: Appending Files `2:42`   - [ ] 20. Python 3 Programming Tutorial: Read from a File `1:49`   - [ ] 21. Python 3 Programming Tutorial: Classes `4:56`   - [ ] 22. Python 3 Programming Tutorial: Frequently Asked Questions `5:33`   - [ ] 23. Python 3 Programming Tutorial: Getting User Input `1:43`   - [ ] 24. Python 3 Programming Tutorial: Statistics (Mean, Standard Deviation) `2:36`   - [ ] 25. Python 3 Programming Tutorial: Module Import Syntax `5:31`   - [ ] 26. Python 3 Programming Tutorial: Making Modules `4:58`   - [ ] 27. Python 3 Programming Tutorial: Lists and Tuples `5:51`   - [ ] 28. Python 3 Programming Tutorial: List Manipulation `9:35`   - [ ] 29. Python 3 Programming Tutorial: Multi-Dimensional List `5:45`   - [ ] 30. Python 3 Programming Tutorial: Reading from a CSV Spreadsheet `9:24`   - [ ] 31. Python 3 Programming Tutorial: Try and Except Error Handlings `7:04`   - [ ] 32. Python 3 Programming Tutorial: Multi-Line Print `3:19`   - [ ] 33. Python 3 Programming Tutorial: Dictionaries `7:11`   - [ ] 34. Python 3 Programming Tutorial: Built-in Functions `10:58`   - [ ] 35. Python 3 Programming Tutorial: OS Module `5:01`   - [ ] 36. Python 3 Programming Tutorial: Sys Module `11:00`   - [ ] 37. Python 3 Programming Tutorial: urllib Module `24:04`   - [ ] 38. Python 3 Programming Tutorial: Regular Expressions/Regex with re `19:58`   - [ ] 39. Python 3 Programming Tutorial: Parsing Websites with re and urllib `7:29`   - [ ] 40. Python 3 Programming Tutorial: Tkinter Module Making Windows `8:03`   - [ ] 41. Python 3 Programming Tutorial: Tkinter Adding Buttons `6:29`   - [ ] 42. Python 3 Programming Tutorial: Tkinter Event Handling `5:40`   - [ ] 43. Python 3 Programming Tutorial: Tkinter Menu Bar `10:25`   - [ ] 44. Python 3 Programming Tutorial: Tkinter Adding Images and Text `11:59`   - [ ] 45. Python 3 Programming Tutorial: Threading Module `18:43`   - [ ] 46. Python 3 Programming Tutorial: cx_freeze Python to .exe `12:08`   - [ ] 47. Python 3 Programming Tutorial: Subprocess Module `13:17`   - [ ] 48. Python 3 Programming Tutorial: Matplotlib Graphing Intro `10:25`   - [ ] 49. Python 3 Programming Tutorial: Matplotlib Labels and Titles `5:03`   - [ ] 50. Python 3 Programming Tutorial: Matplotlib Styles `10:38`   - [ ] 51. Python 3 Programming Tutorial: Matplotlib Legends `4:07`   - [ ] 52. Python 3 Programming Tutorial: Scatter Plots and Bar Charts `6:38`   - [ ] 53. Python 3 Programming Tutorial: Matplotlib Plotting from a CSV `7:21`   - [ ] 54. Python 3 Programming Tutorial: ftplib FTP Transfers Python `8:47`   - [ ] 55. Python 3 Programming Tutorial: Sockets Intro `10:48`   - [ ] 56. Python 3 Programming Tutorial: Sockets Simple Port Scanner `5:08`   - [ ] 57. Python 3 Programming Tutorial: Threaded Port Scanner `9:36`   - [ ] 58. Python 3 Programming Tutorial: Sockets Binding and Listening `5:53`   - [ ] 59. Python 3 Programming Tutorial: Sockets Client Server System `10:27` - [ ] [Intermediate Python Programming](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfju7ADVp5W1GF9jVhjbX-_) by sentdex   - [ ] 1. Intermediate Python Programming: Introduction `7:48`   - [ ] 2. Intermediate Python Programming: String Concatenation and Formatting `13:40`   - [ ] 3. Intermediate Python Programming: Argparse for CLI `10:49`   - [ ] 4. Intermediate Python Programming: List Comprehension and Generator Expressions `6:52`   - [ ] 5. Intermediate Python Programming: More on List Comp and Generators `15:28`   - [ ] 6. Intermediate Python Programming: Timeit Module `11:28`   - [ ] 7. Intermediate Python Programming: Enumerate `4:48`   - [ ] 8. Intermediate Python Programming: Zip `7:23`   - [ ] 9. Intermediate Python Programming: Writing Our Own Generator `11:08`   - [ ] 10. Intermediate Python Programming: Multiprocessing `11:30`   - [ ] 11. Intermediate Python Programming: Getting Returned Values from Processes `4:22`   - [ ] 12. Intermediate Python Programming: Multiprocessing Spider Example `24:18`   - [ ] 13. Intermediate Python Programming: Object Oriented Programming Introductions `11:35`   - [ ] 14. Intermediate Python Programming: Creating an Environment for Our Project `11:49`   - [ ] 15. Intermediate Python Programming: Many Blob Objects `8:30`   - [ ] 16. Intermediate Python Programming: Object Modularity Thoughts `16:41`   - [ ] 17. Intermediate Python Programming: OOP Inheritance `10:17`   - [ ] 18. Intermediate Python Programming: Decorators `8:50`   - [ ] 19. Intermediate Python Programming: Operator Overloading `10:19`   - [ ] 20. Intermediate Python Programming: Detecting Collisions `15:20`   - [ ] 21. Intermediate Python Programming: Special Methods, OOP, Iteration `13:30`   - [ ] 22. Intermediate Python Programming: Logging `15:00`   - [ ] 23. Intermediate Python Programming: Error Handling `6:11`   - [ ] 24. Intermediate Python Programming: --str-- and --repr-- `11:32`   - [ ] 25. Intermediate Python Programming: Args and Kwargs `11:58`   - [ ] 26. Intermediate Python Programming: Asyncio - Asynchronous Programming with Coroutines `28:37` - [ ] [2021 Complete Python Bootcamp From Zero to Hero in Python](https://www.udemy.com/course/complete-python-bootcamp/) by Jose Portilla   - [ ] 1. Course Overview   - [ ] 2. Python Setup   - [ ] 3. Python Object and Data Structure Basics   - [ ] 4. Python Comparison Operators   - [ ] 5. Python Statements   - [ ] 6. Methods and Functions   - [ ] 7. Milestone Project 1   - [ ] 8. Object Oriented Programming   - [ ] 9. Modules and Packages   - [ ] 10. Errors and Exceptions Handlings   - [ ] 11. Milestone Project 2   - [ ] 12. Python Decorators   - [ ] 13. Python Generators   - [ ] 14. Advanced Python Modules   - [ ] 15. Web Scraping with Python   - [ ] 16. Working with Images with Python   - [ ] 17. Working with PDFs and Spreadsheet CSV Files   - [ ] 18. Emails with Python   - [ ] 19. Final Capstone Python Project   - [ ] 20. Advanced Python Objects and Data Structures   - [ ] 21. Bonus Material - Introduction to GUIs - [ ] Build the 5 projects listed in the [5 Intermediate Python Projects](https://www.youtube.com/watch?v=o5sb8ehRSYA&ab_channel=TechWithTim) video by Tech With Tim   - [ ] 1. Build a Website with Django/Flask   - [ ] 2. Use a WebScraper   - [ ] 3. Create a Game with PyGame   - [ ] 4. Build a GUI with Tkinter/PyQt5   - [ ] 5. Robotics/Raspberry Pi Project    ## Data Analysis and Visualization ##### Learn NumPy, Pandas and Matplotlib. - [ ] [Python NumPy Tutorial for Beginners](https://www.youtube.com/watch?v=QUT1VHiLmmI&ab_channel=freeCodeCamp.org) by freeCodeCamp.org `58:09` - [ ] Read the [Introduction to NumPy](https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html) chapter from the Python Data Science Handbook by Jake VanderPlas   - [ ] 1. Introduction to NumPy   - [ ] 2. Understanding Data Types in Python   - [ ] 3. The Basics of NumPy Arrays   - [ ] 4. Computation on NumPy Arrays: Universal Functions   - [ ] 5. Aggregations: Min, Max, and Everything in Between   - [ ] 6. Computation on Arrays: Broadcasting   - [ ] 7. Comparisons, Masks, and Boolean Logic   - [ ] 8. Fancy Indexing   - [ ] 9. Sorting Arrays   - [ ] 10. Structured Data: NumPy's Structured Arrays - [ ] [Pandas Tutorials](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS) by Corey Schafer   - [ ] 1. Python Pandas Tutorial: Getting Started with Data Analysis - Installation and Loading Data `23:01`   - [ ] 2. Python Pandas Tutorial: DataFrame and Series Basics - Selecting Rows and Columns `33:35`   - [ ] 3. Python Pandas Tutorial: Indexes - How to Set, Reset, and Use Indexes `17:27`   - [ ] 4. Python Pandas Tutorial: Filtering - Using Conditionals to Filter Rows and Columns `23:04`   - [ ] 5. Python Pandas Tutorial: Updating Rows and Columns - Modifying Data within DataFrames `40:03`   - [ ] 6. Python Pandas Tutorial: Add/Remove Rows and Columns from DataFrames `16:55`   - [ ] 7. Python Pandas Tutorial: Sorting Data `15:40`   - [ ] 8. Python Pandas Tutorial: Grouping and Aggregating - Analyzing and Exploring Your Data `49:06`   - [ ] 9. Python Pandas Tutorial: Cleaning Data - Casting Data Types and Handling Missing Values `31:54`   - [ ] 10. Python Pandas Tutorial: Working with Dates and Time Series Data `35:41`   - [ ] 11. Python Pandas Tutorial: Reading/Writing Data to Different Sources - Excel, JSON, SQL, Etc. `32:45` - [ ] Read the [Data Manipulation with Pandas](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html) chapter from the Python Data Science Handbook by Jake VanderPlas   - [ ] 1. Data Manipulation with Pandas   - [ ] 2. Introducing Pandas Objects   - [ ] 3. Data Indexing and Selection   - [ ] 4. Operating on Data in Pandas   - [ ] 5. Handling Missing Data   - [ ] 6. Hierarchical Indexing   - [ ] 7. Combining Datasets: Concat and Append   - [ ] 8. Combining Datasets: Merge and Join   - [ ] 9. Aggregation and Grouping   - [ ] 10. Pivot Tables   - [ ] 11. Vectorized String Operations   - [ ] 12. Working with Time Series   - [ ] 13. High-Performance Pandas: eval() and query() - [ ] [Matplotlib Tutorials](https://www.youtube.com/playlist?list=PL-osiE80TeTvipOqomVEeZ1HRrcEvtZB_) by Corey Schafer   - [ ] 1. Matplotlib Tutorial: Creating and Customizing Our First Plots `35:01`   - [ ] 2. Matplotlib Tutorial: Bar Charts and Analyzing Data from CSVs `34:26`   - [ ] 3. Matplotlib Tutorial: Pie Charts `17:02`   - [ ] 4. Matplotlib Tutorial: Stack Plots `14:49`   - [ ] 5. Matplotlib Tutorial: Filling Area on Line Plots `15:18`   - [ ] 6. Matplotlib Tutorial: Histograms `16:36`   - [ ] 7. Matplotlib Tutorial: Scatter Plots `21:24`   - [ ] 8. Matplotlib Tutorial: Plotting Time Series Data `17:09`   - [ ] 9. Matplotlib Tutorial: Plotting Live Data in Real-Time `20:34`   - [ ] 10. Matplotlib Tutorial: Subplots `21:22` - [ ] Read the [Visualization with Matplotlib](https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html) chapter from the Python Data Science Handbook by Jake VanderPlas   - [ ] 1. Visualization with Matplotlib   - [ ] 2. Simple Line Plots   - [ ] 3. Simple Scatter Plots   - [ ] 4. Visualizing Errors   - [ ] 5. Density and Contour Plots   - [ ] 6. Histograms, Binnings, and Density   - [ ] 7. Customizing Plot Legends   - [ ] 8. Customizing Colorbars   - [ ] 9. Multiple Subplots   - [ ] 10. Text and Annotation   - [ ] 11. Customizing Ticks   - [ ] 12. Customizing Matplotlib: Configurations and Stylesheets   - [ ] 13. Three-Dimensional Plotting in Matplotlib   - [ ] 14. Geographic Data with Basemap   - [ ] 15. Visualization with Seaborn - [ ] [Python for Data Science - Course for Beginners (Learn Python, Pandas, NumPy, Matplotlib)](https://www.youtube.com/watch?v=LHBE6Q9XlzI&t=2s&ab_channel=freeCodeCamp.org) by freeCodeCamp.org `12:19:51`  ## Data Preprocessing ##### Learn the basics of data preprocessing. - [ ] [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) by Kaggle   - [ ] 1. Handling Missing Values   - [ ] 2. Scaling and Normalization   - [ ] 3. Parsing Dates   - [ ] 4. Character Encodings   - [ ] 5. Inconsistent Data Entry - [ ] Do the [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic) competition by Kaggle - [ ] Do the [Housing Prices](https://www.kaggle.com/c/home-data-for-ml-course) competition by Kaggle - [ ] [Feature Engineering](https://www.kaggle.com/learn/feature-engineering) by Kaggle   - [ ] 1. Baseline Model   - [ ] 2. Categorical Encodings   - [ ] 3. Feature Generation   - [ ] 4. Feature Selection    ## Databases ##### Learn about databases. - [ ] [Intro to SQL](https://www.kaggle.com/learn/intro-to-sql) by Kaggle   - [ ] 1. Getting Started with SQL and BigQuery   - [ ] 2. Select, From & Where   - [ ] 3. Group By, Having & Count   - [ ] 4. Order By   - [ ] 5. As & With   - [ ] 6. Joining Data - [ ] [Advanced SQL](https://www.kaggle.com/learn/advanced-sql) by Kaggle   - [ ] 1. JOINs and UNIONs   - [ ] 2. Analytic Functions   - [ ] 3. Nested and Repeated Data   - [ ] 4. Writing Efficient Queries - [ ] [MongoDB with Python Crash Course - Tutorial for Beginners](https://www.youtube.com/watch?v=E-1xI85Zog8&ab_channel=freeCodeCamp.org) by freeCodeCamp.org `1:57:33`  ## Machine Learning ##### Taking our first steps into the world of ML. - [ ] [Machine Learning](https://www.coursera.org/learn/machine-learning#syllabus) by Andrew Ng (skipping the MATLAB section)   - [ ] 1. Introduction   - [ ] 2. Linear Regression with One Variable   - [ ] 3. Linear Algebra Review   - [ ] 4. Linear Regression with Multiple Variables   - [ ] 5. Logistic Regression   - [ ] 6. Regularization   - [ ] 7. Neural Networks: Representation   - [ ] 8. Neural Networks: Learning   - [ ] 9: Advice for Applying Machine Learning   - [ ] 10. Machine Learning System Design   - [ ] 11. Support Vector Machines   - [ ] 12. Unsupervised Learning   - [ ] 13. Dimensionality Reduction   - [ ] 14. Anomaly Detection   - [ ] 15. Recommender Systems   - [ ] 16. Large Scale Machine Learning   - [ ] 17. Application Example: Photo OCR - [ ] [Coursera Machine Learning MOOC by Andrew Ng Python Programming Assignments](https://github.com/dibgerge/ml-coursera-python-assignments)   - [ ] Exercise 1   - [ ] Exercise 2   - [ ] Exercise 3   - [ ] Exercise 4   - [ ] Exercise 5   - [ ] Exercise 6   - [ ] Exercise 7   - [ ] Exercise 8 - [ ] Do any [Kaggle](https://www.kaggle.com/) competition - [ ] [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) by Kaggle   - [ ] 1. Introduction   - [ ] 2. Missing Values   - [ ] 3. Categorical Variables   - [ ] 4. Pipelines   - [ ] 5. Cross-Validation   - [ ] 6. XGBoost   - [ ] 7. Data Leakage    ## Linear Algebra and Statistics  ##### Learn linear algebra and statistics. - [ ] [Linear Algebra](https://www.khanacademy.org/math/linear-algebra) on Khan Academy   - [ ] 1. Vectors and Spaces   - [ ] 2. Matrix Transformations   - [ ] 3. Alternate Coordinate Systems (Bases) - [ ] [Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/index.htm) on MIT OpenCourseWare   - [ ] Problem Set 1   - [ ] Problem Set 2   - [ ] Problem Set 3   - [ ] Problem Set 4   - [ ] Problem Set 5   - [ ] Problem Set 6   - [ ] Problem Set 7   - [ ] Problem Set 8   - [ ] Problem Set 9   - [ ] Problem Set 10   - [ ] Exam 1   - [ ] Exam 2   - [ ] Exam 3   - [ ] Final Exam - [ ] [Statistics and Probability](https://www.khanacademy.org/math/statistics-probability) on Khan Academy   - [ ] 1. Analyzing Categorical Data   - [ ] 2. Displaying and Comparing Quantitative Data   - [ ] 3. Summarizing Quantitative Data   - [ ] 4. Modeling Data Distributions   - [ ] 5. Exploring Bivariate Numerical Data   - [ ] 6. Study Design   - [ ] 7. Probability   - [ ] 8. Counting, Permutations, and Combinations   - [ ] 9. Random Variables   - [ ] 10. Sampling Distributions   - [ ] 11. Confidence Intervals   - [ ] 12. Significance Tests (Hypothesis Testing)   - [ ] 13. Two-Sample Inference for the Difference Between Groups   - [ ] 14. Inference for Categorical Data (Chi-Square Tests)   - [ ] 15. Advanced Regression (Inference and Transforming)   - [ ] 16. Analysis of Variance (ANOVA) - [ ] [Introduction to Probability and Statistics](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/index.htm) on MIT OpenCourseWare   - [ ] Problem Set 1   - [ ] Problem Set 2   - [ ] Problem Set 3   - [ ] Problem Set 4   - [ ] Problem Set 5   - [ ] Problem Set 6   - [ ] Problem Set 7   - [ ] Problem Set 8   - [ ] Problem Set 9   - [ ] Exam 1 Practice Questions I   - [ ] Exam 1 Practice Questions II   - [ ] Exam 1 Practice Questions: Long List   - [ ] Exam 1   - [ ] Exam 2 Practice Questions   - [ ] Exam 2   - [ ] Final Exam Practice Questions   - [ ] Final Exam - [ ] [Deep Learning Book](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio & Aaron Courville   - [ ] 1. Introduction   - [ ] 2. Linear Algebra   - [ ] 3. Probability and Information Theory   - [ ] 4. Numerical Computation   - [ ] 5. Machine Learning Basics   - [ ] 6. Deep Feedforward Networks   - [ ] 7. Regularization for Deep Learning   - [ ] 8. Optimization for Training Deep Models   - [ ] 9. Convolutional Networks   - [ ] 10. Sequence Modeling: Recurrent and Recursive Nets   - [ ] 11. Practical Methodology   - [ ] 12. Applications   - [ ] 13. Linear Factor Models   - [ ] 14. Autoencoders   - [ ] 15. Representation Learning   - [ ] 16. Structured Probabilistic Models for Deep Learning   - [ ] 17. Monte Carlo Methods   - [ ] 18. Confronting the Partition Function   - [ ] 19. Approximate Inference   - [ ] 20. Deep Generative Models    ## Deep Learning ##### Learning about deep learning. - [ ] [Practical Deep Learning for Coders](https://course.fast.ai/) by fast.ai   - [ ] Lesson 1   - [ ] Lesson 2   - [ ] Lesson 3   - [ ] Lesson 4   - [ ] Lesson 5   - [ ] Lesson 6   - [ ] Lesson 7   - [ ] Lesson 8 - [ ] [Part 2: Deep Learning from the Foundations](https://course19.fast.ai/part2) by fast.ai   - [ ] Lesson 1   - [ ] Lesson 2   - [ ] Lesson 3   - [ ] Lesson 4   - [ ] Lesson 5   - [ ] Lesson 6   - [ ] Lesson 7   - [ ] Lesson 8   - [ ] Lesson 9   - [ ] Lesson 10   - [ ] Lesson 11   - [ ] Lesson 12   - [ ] Lesson 13   - [ ] Lesson 14 - [ ] [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by Andrew Ng   - [ ] Course 1: Neural Networks and Deep Learning     - [ ] 1. Introduction to Deep Learning     - [ ] 2. Neural Network Basics     - [ ] 3. Shallow Neural Networks     - [ ] 4. Deep Neural Networks   - [ ] Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization     - [ ] 1. Practical Aspects of Deep Learning     - [ ] 2. Optimization Algorithms     - [ ] 3. Hyperparameter tuning, Batch Normalization and Programming Frameworks   - [ ] Course 3: Structuring Machine Learning Projects     - [ ] 1. ML Strategy (1)     - [ ] 2. ML Strategy (2)   - [ ] Course 4: Convolutional Neural Networks     - [ ] 1. Foundations of Convolutional Neural Networks     - [ ] 2. Deep Convolutional Models: Case Studies     - [ ] 3. Object Detection     - [ ] 4. Special applications: Face recognition & Neural style transfer   - [ ] Course 5: Sequence Models     - [ ] 1. Recurrent Neural Networks     - [ ] 2. Natural Language Processing & Word Embeddings     - [ ] 3. Sequence Models & Attention Mechanism - [ ] [DeepLearning.AI TensorFlow Developer Professional Certificate](https://www.coursera.org/professional-certificates/tensorflow-in-practice?) by Laurence Moroney   - [ ] Course 1: Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning     - [ ] 1. A New Programming Paradigm     - [ ] 2. Introduction to Computer Vision     - [ ] 3. Enhancing Vision with Convolutional Neural Networks     - [ ] 4. Using Real-World Images   - [ ] Course 2: Convolutional Neural Networks in TensorFlow     - [ ] 1. Exploring a Larger Dataset     - [ ] 2. Augmentation: A Technique to Avoid Overfitting     - [ ] 3. Transfer Learning     - [ ] 4. Multiclass Classifications   - [ ] Course 3: Natural Language Processing in TensorFlow     - [ ] 1. Sentiment in Text     - [ ] 2. Word Embeddings     - [ ] 3. Sequence Models     - [ ] 4. Sequence Models and Literature   - [ ] Course 4: Sequences, Time Series and Prediction     - [ ] 1. Sequences and Prediction     - [ ] 2. Deep Neural Networks for Time Series     - [ ] 3. Recurrent Neural Networks for Time Series     - [ ] 4. Real-World Time Series Data      ##  Cloud for Model Deployment ##### Learn how to build, train, test, and deploy a machine learning model on AWS. - [ ] [AWS Machine Learning Specialty](https://www.youtube.com/playlist?list=PLEF5xKHm-3ZNDvdJpMCLu9xa1oDNvAmMr) by Amazon   - [ ] 1. AWS Training and Certification: Machine Learning `1:31`   - [ ] 2. Build, Train and Deploy Machine Learning Models on AWS with Amazon SageMaker - AWS Online `35:51`   - [ ] 3. AWS re:Invent 2018: Leadership Session: Machine Learning (AIM202-L) `58:01`   - [ ] 4. Machine Learning Models with TensorFlow Using Amazon SageMaker - AWS Online Tech Talks `40:16`   - [ ] 5. AWS re:Invent 2018: Build & Deploy ML Models Quickly & Easily with Amazon SageMaker `57:53`   - [ ] 6. AWS re:Invent 2018: CI/CD for Your Machine Learning Pipeline with Amazon SageMaker `57:13`   - [ ] 7. AWS Berlin Summit 2018 - Building and Running Your First ML Application on Amazon SageMaker `52:54`   - [ ] 8. Predictive Analytics with Amazon SageMaker `1:03:29`   - [ ] 9. AWS re:Invent 2018: AI/ML with Data Lakes: Counterintuitive Consumer Insights in Retail `1:00:10`   - [ ] 10. AWS re:Invent 2018: Industrialize Machine Learning Using CI/CD Techniques (FSV304-i) `45:34`   - [ ] 11. AWS re:Invent 2018: Driving Machine Learning and Analytics Use Cases with AWS Storage (STG302) `40:16`   - [ ] 12. AWS re:Invent 2018: Deep Learning Applications Using TensorFlow (AIM401-R) `1:02:29`   - [ ] 13. AWS re:Invent 2017: Machine Learning State of the Union (MCL210) `1:00:55`   - [ ] 14. AWS re:Invent 2017: Containerized Machine Learning on AWS (CON309) `1:03:21`   - [ ] 15. AWS re:Invent 2017: Introduction to Deep Learning (MCL205) `46:17`   - [ ] 16. Continuous Delivery with AWS CodePipeline and Amazon SageMaker `25:24`   - [ ] 17. AWS re:Invent 2017: Best Practices for Distributed Machine Learning and Predictive A (ABD403) `1:16:16`   - [ ] 18. AWS re:Invent 2017: GPS: Enhancing Customer Security Using AI/ML on AWS (GPSTEC311) `50:21`   - [ ] 19. How to Wrangle Data for Machine Learning on AWS `59:24`   - [ ] 20. Extract Data from Images and Videos with Amazon Rekognition (Level 300) `26:52`   - [ ] 21. Exploring the Business Use Cases for Amazon Machine Learning - 2017 AWS Online Tech Talks `30:35`   - [ ] 22. AWS re:Invent 2017: Orchestrating Machine Learning Training for Netflix Recommendation (MCL317) `54:21`   - [ ] 23. AWS re:Invent 2017: Reinforcement Learning - The Ultimate AI (ARC320) `1:00:00`   - [ ] 24. Amazon Machine Learning: Empowering Developers to Build Smart Applications `55:09`   - [ ] 25. Amazon SageMaker's Built-in Algorithm Webinar Series: DeepAR Forecasting `53:41`   - [ ] 26. Amazon SageMaker's Built-in Algorithm Webinar Series: Linear Learner `58:55`   - [ ] 27. Amazon SageMaker's Built-in Algorithm Webinar Series: Clustering with K Means `58:52`   - [ ] 28. Amazon SageMaker's Built-in Algorithm Webinar Series: Latent Dirichlet Allocation (LDA) `57:25`   - [ ] 29. Amazon SageMaker's Built-in Algorithm Webinar Series: XGBoost `1:01:02`   - [ ] 30. Amazon SageMaker's Built-in Algorithm Webinar Series: ResNet `55:56`   - [ ] 31. Amazon SageMaker-s Built-in Algorithm Webinar Series: Blazing Text `1:14:37`   - [ ] 32. AWS re:Invent 2017: NEW LAUNCH! Introducing Amazon SageMaker (MCL365) `1:02:08`   - [ ] 33. Fully Managed Notebook Instances with Amazon SageMaker - a Deep Dive `16:45`   - [ ] 34. Built-in Machine Learning Algorithms with Amazon SageMaker -  a Deep Dive `15:38` - [ ] [Machine Learning with TensorFlow on Google Cloud Platform Specialization](https://www.coursera.org/specializations/machine-learning-tensorflow-gcp) by Google Cloud Training   - [ ] Course 1: How Google does Machine Learning     - [ ] 1. Introduction to Course     - [ ] 2. What It Means to Be AI First     - [ ] 3. How Google Does ML     - [ ] 4. Inclusive ML     - [ ] 5. Python Notebooks in the Cloud     - [ ] 6. Summary   - [ ] Course 2: Launching into Machine Learning     - [ ] 1. Introduction to Course     - [ ] 2. Improve Data Quality and Exploratory Data Analysis     - [ ] 3. Practical ML     - [ ] 4. Optimization     - [ ] 5. Generalization and Sampling     - [ ] 6. Summary   - [ ] Course 3: Introduction to TensorFlow     - [ ] 1. Introduction to Course     - [ ] 2. Introduction to TensorFlow     - [ ] 3. Design and Build a TensorFlow Input Data Pipeline     - [ ] 4. Training Neural Networks with TensorFlow 2 and the Keras Sequential API     - [ ] 5. Training Neural Networks with TensorFlow 2 and the Keras Functional API     - [ ] 6. Summary   - [ ] Course 4: Feature Engineering     - [ ] 1. Introduction to Course     - [ ] 2. Raw Data to Features     - [ ] 3. Preprocessing and Feature Creation     - [ ] 4. Feature Crosses     - [ ] 5. TensorFlow Transform     - [ ] 6. Summary   - [ ] Course 5: Art and Science of Machine Learning     - [ ] 1. Introduction     - [ ] 2. The Art of ML     - [ ] 3. Hyperparameter Tuning     - [ ] 4. A Pinch of Science     - [ ] 5. The Science of Neural Networks     - [ ] 6. Embeddings     - [ ] 7. Summary",0,0,0,database+sequence+analysis,GitHub
