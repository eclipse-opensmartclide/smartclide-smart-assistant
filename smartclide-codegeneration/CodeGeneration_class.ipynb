{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirment install\n",
    "\n",
    "# !pip intstall tensorflow\n",
    "# !pip intstall requests\n",
    "# !pip intstall pandas numpy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import string \n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tensorflow\n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras  import models\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class CodeGeneration:\n",
    "    X=[]\n",
    "    y=[]\n",
    "    seqXLength=0\n",
    "    codeVocabSize=0\n",
    "    modelLSTM=Sequential()\n",
    "    df = pd.DataFrame() ;\n",
    "    rawCodeList = [] ;\n",
    "    EncodedCodes=[];\n",
    "    token=Tokenizer(lower=False, filters='!\"#$%&*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n');\n",
    "    codeLineCoulmn=\"codes\";\n",
    "    defaultDatasetPath=\"data/top_poject_source_codes.csv\";\n",
    "    coustomDatasetLine=2000\n",
    "    nGramcodeList=[]\n",
    "    maxLengthPadding=40\n",
    "    paddedCodeNgramSequences=[]\n",
    "    predictCodeLength=2\n",
    "    _Epochs=140\n",
    "    _Batch_size=64\n",
    "    _Use_saved_model=True;\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    def __init__( self,lang, level,token=''):\n",
    "        self.lang = lang\n",
    "        self.level = level\n",
    "\n",
    "   \n",
    "    def loadCodeData(self):\n",
    "        self.df=pd.read_csv(self.defaultDatasetPath)\n",
    "        #         print(self.defaultDatasetPath)\n",
    "        self.df=self.df[:self.coustomDatasetLine]\n",
    "        return (self.df)\n",
    "        \n",
    "\n",
    "    def codeToRawCodeList(self):\n",
    "        self.rawCodeList=self.df[self.codeLineCoulmn].tolist()\n",
    "        return (self.rawCodeList)\n",
    "\n",
    "\n",
    "    def getTotalWords(self):\n",
    "        return len(\" \".join(self.rawCodeList))\n",
    "    \n",
    "    def getWordFrequencyCounts(self):\n",
    "        self.tokenizeCodes()\n",
    "        self.encodeWords()\n",
    "        return len(\" \".join(self.rawCodeList))    \n",
    "    \n",
    "    def totalWords(self):\n",
    "        return len(\" \".join(self.rowcodeList))\n",
    "    \n",
    "    def tokenizeCodes(self):\n",
    "        self.token.fit_on_texts(self.rawCodeList)\n",
    "        self.EncodedCodes=self.token.texts_to_sequences(self.rawCodeList)\n",
    "        return self.EncodedCodes\n",
    "        \n",
    "    def encodedWordsCount(self):\n",
    "        self.tokenizeCodes();\n",
    "        word_counts=self.token.word_counts\n",
    "        return word_counts\n",
    "        \n",
    "    def encodedWordsIndex(self):\n",
    "        self.tokenizeCodes();\n",
    "        word_index=self.token.word_index\n",
    "        return word_index   \n",
    "    \n",
    "    \n",
    "    def encodedWordsIndex(self):\n",
    "        self.tokenizeCodes();\n",
    "        word_index=self.token.word_index\n",
    "        return word_index   \n",
    "    \n",
    "    def getAllCodesWordSize(self):\n",
    "        vocabSize=len(self.token.word_counts)+1\n",
    "        return vocabSize     \n",
    "\n",
    "    \n",
    "    #break each line as ngram \n",
    "    def provideNgramSequences(self):\n",
    "        nGramcodeList=[]\n",
    "\n",
    "        for d in self.EncodedCodes:\n",
    "            if len(d)>1:           \n",
    "                for i in range(2,len(d)):\n",
    "                    nGramcodeList.append(d[:i])\n",
    "#                     print (d[:i])\n",
    "        self.nGramcodeList=nGramcodeList            \n",
    "        return nGramcodeList;\n",
    "                    \n",
    "    #provide padding input for ML or DL algorithms                \n",
    "    def nGramcodeSeqPadding(self): \n",
    "        self.paddedCodeNgramSequences=pad_sequences(self.nGramcodeList, maxlen=self.maxLengthPadding,padding=\"pre\")\n",
    "        return self.paddedCodeNgramSequences\n",
    "    \n",
    "    \n",
    "    def provideModelInputOutPut(self):\n",
    "        self.X=self.paddedCodeNgramSequences[:,:-1] \n",
    "        self.y=self.paddedCodeNgramSequences[:,-1]\n",
    "        \n",
    "        #categorize y\n",
    "        self.codeVocabSize=self.getAllCodesWordSize()\n",
    "        self.y=to_categorical(self.y,num_classes=self.codeVocabSize)\n",
    "        #X shape\n",
    "        self.seqXLength=self.X.shape[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def TrainLSTMModel(self):\n",
    "\n",
    "        self.modelLSTM=Sequential()\n",
    "        self.modelLSTM.add(Embedding(self.codeVocabSize,50,input_length=self.seqXLength))\n",
    "        self.modelLSTM.add(LSTM(100,return_sequences=True))\n",
    "        self.modelLSTM.add(LSTM(100))\n",
    "        self.modelLSTM.add(Dense(100,activation=\"relu\"))\n",
    "        self.modelLSTM.add(Dense(self.codeVocabSize,activation=\"softmax\"))\n",
    "#         self.modelLSTM.summary()\n",
    "\n",
    "        self.modelLSTM.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "        self.modelLSTM.fit(self.X,self.y, batch_size=self._Batch_size,epochs=self._Epochs)\n",
    "        \n",
    "        self.modelLSTM.save('saved_model/LSTM_code_generatiion_model')\n",
    "\n",
    "        \n",
    "        \n",
    "    def plotModelResult(self):    \n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if _Use_saved_model==True:\n",
    "            return True;\n",
    "        \n",
    "        \n",
    "    def loadSavedModel(self):\n",
    "\n",
    "        isfile =os.path.exists(os.path.join(os.getcwd(), './saved_model/LSTM_code_generatiion_model', 'saved_model.pb'))\n",
    "        if  isfile:     \n",
    "            self.modelLSTM = tensorflow.keras.models.load_model('saved_model/LSTM_code_generatiion_model')\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "    def generate_code(self,seed_text,n_lines):\n",
    "        \n",
    "        self.loadCodeData()\n",
    "        self.codeToRawCodeList()\n",
    "        self.tokenizeCodes()\n",
    "        self.encodedWordsCount()\n",
    "        self.provideNgramSequences()\n",
    "        self.nGramcodeSeqPadding()\n",
    "        \n",
    "        self.provideModelInputOutPut()\n",
    "\n",
    "        isDir =os.path.isdir('./saved_model') \n",
    "        isfile =os.path.exists(os.path.join(os.getcwd(), './saved_model/LSTM_code_generatiion_model', 'saved_model.pb'))\n",
    "\n",
    "        \n",
    "        #load saved model\n",
    "        if self._Use_saved_model==True and isDir and isfile:\n",
    "                self.loadSavedModel()\n",
    "        else:\n",
    "                self.TrainLSTMModel()\n",
    "        \n",
    "        predictionList= []    \n",
    "        seq_length=self.seqXLength\n",
    "\n",
    "        for i in range(n_lines):\n",
    "            text=[]\n",
    "            for _ in range(self.predictCodeLength):\n",
    "                encoded=self.token.texts_to_sequences([seed_text])\n",
    "                encoded=pad_sequences(encoded,maxlen=seq_length,padding='pre')\n",
    "\n",
    "                y_pred=np.argmax( self.modelLSTM.predict(encoded),axis=1)\n",
    "\n",
    "                #find to word dictinary which word mapped number\n",
    "                predicted_code=\"\"\n",
    "                for word,index in self.token.word_index.items():\n",
    "                    if index== y_pred:\n",
    "                        predicted_code=word\n",
    "                        break\n",
    "                seed_text=seed_text +' '+ predicted_code\n",
    "                text.append(predicted_code)\n",
    "\n",
    "            seed_text=text[-1]\n",
    "            text=' '.join(text) \n",
    "            print(text)\n",
    "            predictionList.append(text)\n",
    "        \n",
    "        return   predictionList\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android support\n"
     ]
    }
   ],
   "source": [
    "#sample Code\n",
    "codeGenObj=CodeGeneration('Java','line')\n",
    "\n",
    "#sample1\n",
    "seed_text='import'\n",
    "predictionList=codeGenObj.generate_code(seed_text,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "com viewpagerindicator\n",
      "measureSpec packed\n"
     ]
    }
   ],
   "source": [
    "#sample 2\n",
    "\n",
    "seed_text='package'\n",
    "predictionList=codeGenObj.generate_code(seed_text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
